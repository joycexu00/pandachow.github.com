---
layout: post
title: 模拟退火算法学习笔记(一)
categories:
- 伪技术
tags:
- MATLAB
- 人工智能
- 数学建模
- 算法
---

淡疼又在复习模拟退火了, 大概智能算法里面除了神经网络就这个还算熟一点把, 毕竟去年的CUMCM就是拿退火做的最后一问, 虽然结果不是太好, 但也算是靠他最后得到结果了. 貌似很久没用又有一点忘掉了, 复习复习把. o_O#

**退火参数简单说明**
退火过程由一组初始的参数, 就是冷却进度表(cooling schedule)来控制, 它的核心是尽量使系统达到准平衡, 以使算法在有限的时间内逼近最优解. 这个所谓的冷却进度表包括这么几个参数:
1. 控制参数的初值$$T_0$$: 冷却开始的温度.
2. 控制参数的衰减参数$$T$$的衰减函数: 因为我们的计算机能够处理的都是离散的数据, 因此也是需要把连续的降温过程离散化成降温过程中的一系列温度点, 衰减函数即计算这一系列温度的函数表达式.
3. 控制参数$$T$$的终值$$T_f$$(就是停止准则, 或者是算法停止条件).
4. Markov链的长度$$L_k$$: 任一温度$$T$$的迭代次数.

**算法基本步骤**
这里的步骤也只是简单的说说, 并不是非常详细, 大概也只是个基本的步骤.
1. 令$$T=T_0$$, 即开始退火的初始温度, 随机生成一个初始解$$x_0$$, 并记算相应的目标函数值$$E(x_0)$$.
2. 令$$T$$等于冷却进度表中的下一个值$$T_i$$.
3. 根据当前解$$x_i$$进行扰动(对于这个扰动暂时可以认为是一个干扰函数或者是一个噪声之类的东西o_O), 从而产生一个新解$$x_j$$, 计算相应的目标函数$$E(x_j)$$, 得到$$\Delta E=E(x_j)-E(x_i)$$.
4. 如果$$\Delta0$$, 则新解$$x_j$$按概率$$e^{-\frac{\Delta E}{T_i}}$$接受, $$T_i$$为当前温度.
5. 在温度$$T_i$$下, 重复$$L_k$$次的扰动和接受过程, 也就是重复执行步骤3和4.
6. 判断$$T$$是否已经达到$$T_f$$, 如果达到, 则终止算法; 反之, 就转到步骤2并且继续执行.

这里需要注意的一点是, 由于算法是有着随机性的, 因此虽然在算法终止的时候, 也就是低温的时候接受函数已经非常小了, 但是仍然不排除会有更差的解, 因此一般都会把退火过程中得到的比较好的解(或者是历史最优解)都会保存下来.

**Some tips:**
为了更好的实现SA, 还哟一些问题需要注意.
**1. something about 新解**
前面已经知道, 我们新解的产生的机制的基本要求是能够尽量遍及解空间的各个区域, 这样在某一个恒定的温度不断产生新解的时候, 就可能跳出当前区域的局部极小, 从而来搜索其他区域, 这也是SA算法能够进行广域搜索的一个重要的条件.

**2. 状态表达**
由于SA算法的本质和来源于现实生活中的退火过程, 后者说SA算法中优化问题的一个解模拟了退火过程中固体内部的一种粒子分布情况. 这里的状态表达也即是指实际状态的解如何来以一种合适的数学形式表达出来, 它应当要适用于SA的求解, 又能充分表达了实际的问题, 当然了, 这个是需要仔细斟酌来设计的, 背后需要付出很多工作的.
当然同属只能算法, 我个人觉得还是可以适当参考一下遗传算法和紧急搜索中编码部分的内容的. 一些常见的编码方式也是可以作为参考的, 比如
	
  * 背包问题和指派问题的0-1编码
  * TSP问题和调度问题的自然书编码问题
  * 用于连续函数优化的实数编码

**3. 收敛的一般性条件**
	
  1. 初始温度足够高
  2. 热平衡时间足够长
  3. 终止温度足够低
  4. 降温过程足够缓慢

但是上面的这些条件在应用中很难同时满足, 一般常常都是要依赖各个参数来进行适当的折中处理.

**4. 参数的选择**

**控制参数$$T$$的初值$$T_0$$**
对于求解全局的优化问题, 我们通常使用的随机搜索算法都是采用的大范围的粗略搜索与局部的精细搜索相结合的搜索策略. 而且, 只有在最初的大范围的搜索阶段能够找到全局最优解所在的区域, 才能在后面的搜索过程中逐渐减小缩小范围, 最终才能求出全局最优解. SA也是通过调整初值$$T_0$$和衰减函数来实现大范围的区域粗略搜索和局部的精细搜索. 从理论的角度来说, 只有$$T_0$$足够大才能满足算法要求, 但是显然这里的足够大并不是一个准确的值, 有的题目100就够了, 有的题目恐怕还是需要1000+的. 通常$$T_0$$如果过小还是会导致算法难以跳出局部沦陷而达不到全局最优. 但是也不能一味的选择过大, 计算量实在是必须要考虑的问题, 应该和其他的参数进行折中考虑.

**控制参数$$T$$的衰减函数**
衰减函数的形式有很多, 一个比较常见也是比较长用的函数是:
$$!T_{k+1}=\alpha T_k, k=1, 2, \cdots$$
其中, $$\alpha$$是一个常数, 可以取值为$$0.5~0.99$$, 只要比1小就行了, 当然这个取值会影响到降温的过程. 衰减量比较小可以使算法迭代的次数增加, 从而使算法进程接受更多的变换, 从而能够访问更多的领域, 搜索更大范围的解空间, 也有更大的可能返回得到更好地最终解. 同时由于在$$T_k$$上已经达到了准平衡, 则在$$T_{k+1}$$的时候只需要少量的变换就可以达到准平衡. 这样就可以选取长度较短的Markov链来减少算法时间.

**Markov链长度**
这个我也说不好, 个人没有太多理解, 随机过程没有学过, 从实践的角度来说, 相对简单的情况就是可以令$$L_k=100n$$, n是问题的规模.

**算法停止准则**
对Metropolis准则(名字还挺有意思的, 不过这个词好像GRE没背过, 面壁...)中的接受函数$$e^{\frac{-(E_j-E_i)}{kT}}$$分析可以知道, 在$$T$$比较大的高温的情况下, 指数上的分母比较大, 而这又是一个负指数, 所以整个接受函数可能会趋于1, 即比当前解更差的解也有可能被接受, 这样才有可能跳出局部最极小而进行广域搜索, 从而去搜索解空间的其他区域; 而随着冷却的进行, $$T$$减小到一个比较小的值的时候, 接受函数分母小了, 整体也就小了, 换句话说也就是更难于接受比当前解更差的解, 也就是比较难以跳出当前的区域. 但是如果在高温的时候已经进行了充分的广域搜索, 找到了可能的存在最好解的区域, 那么在低温下再进行足够的局部搜索, 那么就有可能得到全局最优解. 因此, 一般来说, $$T_j$$应该设为一个足够小的正数, 比如0.01~5, 但是话说回来, 这也只是一个比较粗糙的数值.
